# ./pyspark
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 1.4.0
      /_/

Using Python version 2.6.9 (unknown, Sep  9 2014 15:05:12)
SparkContext available as sc, SQLContext available as sqlContext.
>>> a = [('g1', 2), ('g2', 4), ('g3', 3), ('g4', 8)]
>>> a
[('g1', 2), ('g2', 4), ('g3', 3), ('g4', 8)]

>>> rdd = sc.parallelize(a);
>>> rdd.collect()
[('g1', 2), ('g2', 4), ('g3', 3), ('g4', 8)]

>>> sorted = rdd.sortByKey()
>>> sorted.collect()
[('g1', 2), ('g2', 4), ('g3', 3), ('g4', 8)]


>>> rdd2 = rdd.map(lambda (x,y) : (y,x))
>>> rdd2.collect()
[(2, 'g1'), (4, 'g2'), (3, 'g3'), (8, 'g4')]

>>> sorted = rdd2.sortByKey()
>>> sorted.collect()
[(2, 'g1'), (3, 'g3'), (4, 'g2'), (8, 'g4')]


>>> sorted = rdd2.sortByKey(False)
>>> sorted.collect()
[(8, 'g4'), (4, 'g2'), (3, 'g3'), (2, 'g1')]

>>> sorted = rdd2.sortByKey()
>>> sorted.collect()
[(2, 'g1'), (3, 'g3'), (4, 'g2'), (8, 'g4')]
>>>
>>> list
[(2, 'g1'), (3, 'g3'), (4, 'g2'), (8, 'g4')]

>>>
>>> sorted.collect()
[(2, 'g1'), (3, 'g3'), (4, 'g2'), (8, 'g4')]

>>> indices = sorted.zipWithIndex()
>>> indices.collect()
[((2, 'g1'), 0), ((3, 'g3'), 1), ((4, 'g2'), 2), ((8, 'g4'), 3)]
>>>